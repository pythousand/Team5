{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8428809,"sourceType":"datasetVersion","datasetId":5019236},{"sourceId":8428850,"sourceType":"datasetVersion","datasetId":5019268}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import random\n","import pandas as pd\n","import numpy as np\n","import os\n","import re\n","import glob\n","import cv2\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","import torchvision.models as models\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import classification_report\n","from tqdm import tqdm\n","import warnings\n","import matplotlib.pyplot as plt\n","from PIL import Image,ImageOps\n","warnings.filterwarnings(action='ignore')\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-20T04:38:06.914503Z","iopub.execute_input":"2024-05-20T04:38:06.914873Z","iopub.status.idle":"2024-05-20T04:38:14.711733Z","shell.execute_reply.started":"2024-05-20T04:38:06.914841Z","shell.execute_reply":"2024-05-20T04:38:14.710738Z"},"trusted":true,"id":"NChOsi7Fr5hV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CFG={\n","    'IMG_SIZE':256,\n","    'BATCH_SIZE':16,\n","    'LEARNING_RATE':1e-5,\n","    'SEED':42,\n","    'EPOCHS':5\n","}"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:38:15.755514Z","iopub.execute_input":"2024-05-20T04:38:15.755990Z","iopub.status.idle":"2024-05-20T04:38:15.760945Z","shell.execute_reply.started":"2024-05-20T04:38:15.755963Z","shell.execute_reply":"2024-05-20T04:38:15.759942Z"},"trusted":true,"id":"WubrlV-ar5hX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(CFG['SEED'])"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:38:16.523115Z","iopub.execute_input":"2024-05-20T04:38:16.523941Z","iopub.status.idle":"2024-05-20T04:38:16.531458Z","shell.execute_reply.started":"2024-05-20T04:38:16.523912Z","shell.execute_reply":"2024-05-20T04:38:16.530667Z"},"trusted":true,"id":"fZr8BxZxr5hY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_path='/kaggle/input/labels/label'\n","train_label_path=os.path.join(label_path,'train')\n","val_label_path=os.path.join(label_path,'val')\n","label_json_list=['anger.json','happy.json','panic.json','sadness.json']"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:38:17.458705Z","iopub.execute_input":"2024-05-20T04:38:17.459054Z","iopub.status.idle":"2024-05-20T04:38:17.464002Z","shell.execute_reply.started":"2024-05-20T04:38:17.459027Z","shell.execute_reply":"2024-05-20T04:38:17.463066Z"},"trusted":true,"id":"-9VflczGr5hY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df=pd.DataFrame(columns=['img_path','gender','age','maxX','maxY','minX','minY','label'])\n","val_df=pd.DataFrame(columns=['img_path','gender','age','maxX','maxY','minX','minY','label'])"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:42:12.864991Z","iopub.execute_input":"2024-05-20T04:42:12.865740Z","iopub.status.idle":"2024-05-20T04:42:12.873460Z","shell.execute_reply.started":"2024-05-20T04:42:12.865707Z","shell.execute_reply":"2024-05-20T04:42:12.872425Z"},"trusted":true,"id":"Tt-qfwTdr5hY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_image_path_dict=dict()\n","val_image_path_dict=dict()\n","exp=['anger','happy','panic','sadness']"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:42:14.421446Z","iopub.execute_input":"2024-05-20T04:42:14.421782Z","iopub.status.idle":"2024-05-20T04:42:14.426946Z","shell.execute_reply.started":"2024-05-20T04:42:14.421757Z","shell.execute_reply":"2024-05-20T04:42:14.425904Z"},"trusted":true,"id":"2zzDCRE2r5hZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shutil\n","extension=set()\n","for i in range(1,8):\n","    path='/kaggle/input/images/img-00'+str(i)+'/img/'\n","    if os.path.isdir(os.path.join(path,'train')):\n","        train_path=os.path.join(path,'train')\n","    if os.path.isdir(os.path.join(path,'val')):\n","        val_path=os.path.join(path,'val')\n","    for j in exp:\n","        if os.path.isdir(os.path.join(train_path,j)):\n","            train_exp_path=os.path.join(train_path,j)\n","        if os.path.isdir(os.path.join(val_path,j)):\n","            val_exp_path=os.path.join(val_path,j)\n","        for j in [train_exp_path,val_exp_path]:\n","            cate=j.split('/')[-2]\n","            for f in os.listdir(j):\n","                src=os.path.join(j,f)\n","                extension.add(f.split('.')[-1])\n","                if cate=='train':\n","                    train_image_path_dict[f]=src\n","                else:\n","                    val_image_path_dict[f]=src"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:42:14.679774Z","iopub.execute_input":"2024-05-20T04:42:14.680087Z","iopub.status.idle":"2024-05-20T04:42:14.774479Z","shell.execute_reply.started":"2024-05-20T04:42:14.680060Z","shell.execute_reply":"2024-05-20T04:42:14.773699Z"},"trusted":true,"id":"C4Fpj5XWr5hZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","from statistics import median\n","def make_df(dir_path,df,image_path_dict):\n","    i=0\n","    data_name=dir_path.split('/')[-1]\n","    for label_name in label_json_list:\n","        with open(os.path.join(dir_path,data_name+'_'+label_name),'r',encoding='cp949') as f:\n","            file=json.load(f)\n","        for v in file:\n","            if v['filename'].split('.')[-1]=='jpeg':\n","                continue\n","            if v['gender']=='남':\n","                gender=0\n","            else:\n","                gender=1\n","            if v['faceExp_uploader']=='분노':\n","                label='anger'\n","            elif v['faceExp_uploader']=='기쁨':\n","                label='happy'\n","            elif v['faceExp_uploader']=='당황':\n","                label='panic'\n","            elif v['faceExp_uploader']=='슬픔':\n","                label='sadness'\n","            minX=median([v['annot_A']['boxes']['minX'], v['annot_B']['boxes']['minX'], v['annot_C']['boxes']['minX']])\n","            minY=median([v['annot_A']['boxes']['minY'], v['annot_B']['boxes']['minY'], v['annot_C']['boxes']['minY']])\n","            maxX=median([v['annot_A']['boxes']['maxX'], v['annot_B']['boxes']['maxX'], v['annot_C']['boxes']['maxX']])\n","            maxY=median([v['annot_A']['boxes']['maxY'], v['annot_B']['boxes']['maxY'], v['annot_C']['boxes']['maxY']])\n","\n","            df.loc[i]=[image_path_dict[v['filename']],gender,v['age'],int(maxX),int(maxY),int(minX),int(minY),label]\n","            i+=1\n","    return df.sample(frac=1).reset_index(drop=True)"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:43:46.131535Z","iopub.execute_input":"2024-05-20T04:43:46.132530Z","iopub.status.idle":"2024-05-20T04:43:46.145763Z","shell.execute_reply.started":"2024-05-20T04:43:46.132495Z","shell.execute_reply":"2024-05-20T04:43:46.144486Z"},"trusted":true,"id":"EfF5ro0Jr5ha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df=make_df(train_label_path,train_df,train_image_path_dict)\n","val_df=make_df(val_label_path,val_df,val_image_path_dict)"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:43:48.098364Z","iopub.execute_input":"2024-05-20T04:43:48.098699Z","iopub.status.idle":"2024-05-20T04:43:57.209208Z","shell.execute_reply.started":"2024-05-20T04:43:48.098675Z","shell.execute_reply":"2024-05-20T04:43:57.208369Z"},"trusted":true,"id":"Po6aQzjFr5ha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","le=LabelEncoder()\n","train_df['label']=le.fit_transform(train_df['label'])\n","val_df['label']=le.transform(val_df['label'])"],"metadata":{"trusted":true,"id":"3LNLL5-zr5ha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","fig, axs = plt.subplots(nrows=1, ncols=5, figsize=(20, 20))\n","for i in range(5):\n","    image_file = train_df.loc[i,'img_path']\n","    minY, minX, maxX, maxY = map(int, [train_df.loc[i,'minY'], train_df.loc[i,'minX'], train_df.loc[i,'maxX'], train_df.loc[i,'maxY']])\n","    img=cv2.imread(image_file)\n","    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","    img=img[minY:maxY,minX:maxX]\n","    axs[i].imshow(img)\n","    axs[i].axis('off')\n","    axs[i].set_title(le.classes_[train_df.loc[i,'label']], size='large')"],"metadata":{"trusted":true,"id":"ZULVMEbir5hb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import timm\n","model = timm.create_model('timm/swinv2_large_window12to16_192to256.ms_in22k_ft_in1k', pretrained=True,num_classes=1)\n","model = torch.nn.DataParallel(model)\n"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:01:44.671449Z","iopub.execute_input":"2024-05-20T05:01:44.672313Z","iopub.status.idle":"2024-05-20T05:01:48.702892Z","shell.execute_reply.started":"2024-05-20T05:01:44.672271Z","shell.execute_reply":"2024-05-20T05:01:48.702109Z"},"trusted":true,"id":"3PqTtiwcr5hb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.transforms import Compose, Resize, Normalize, ToTensor,RandomHorizontalFlip,RandomRotation,ColorJitter\n","class CustomDataset(Dataset):\n","    def __init__(self, img_path, gender, maxX, maxY, minX, minY, transforms=None):\n","        self.img_path = img_path\n","        self.transforms = transforms\n","        self.maxX = maxX\n","        self.maxY = maxY\n","        self.minX = minX\n","        self.minY = minY\n","        self.gender = gender\n","\n","    def __getitem__(self, index):\n","        image_path = self.img_path[index]\n","        image = Image.open(image_path).convert(\"RGB\")\n","        image = ImageOps.exif_transpose(image)\n","        minY, minX, maxX, maxY = int(self.minY[index]), int(self.minX[index]), int(self.maxX[index]), int(self.maxY[index])\n","        image = image.crop((minX, minY, maxX, maxY))\n","\n","        if self.transforms is not None:\n","            image = self.transforms(image)\n","        if self.gender is not None:\n","            gender=self.gender[index]\n","            return image, gender\n","        else:\n","            return image\n","\n","    def __len__(self):\n","        return len(self.img_path)\n","\n","train_transform = Compose([\n","    Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n","    ToTensor(),\n","    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","])\n","\n","test_transform = Compose([\n","    Resize((CFG['IMG_SIZE'],CFG['IMG_SIZE'])),\n","    ToTensor(),\n","    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","])\n","train_ds=CustomDataset(train_df['img_path'].values,train_df['gender'].values,train_df['maxX'].values,train_df['maxY'].values,train_df['minX'].values,train_df['minY'].values,train_transform)\n","val_ds=CustomDataset(val_df['img_path'].values,val_df['gender'].values,val_df['maxX'].values,val_df['maxY'].values,val_df['minX'].values,val_df['minY'].values,test_transform)\n","train_loader=DataLoader(train_ds,batch_size=CFG['BATCH_SIZE'],shuffle=True,num_workers=0)\n","val_loader=DataLoader(val_ds,batch_size=CFG['BATCH_SIZE'],shuffle=False,num_workers=0)"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:52:43.402203Z","iopub.execute_input":"2024-05-20T04:52:43.402929Z","iopub.status.idle":"2024-05-20T04:52:43.417686Z","shell.execute_reply.started":"2024-05-20T04:52:43.402897Z","shell.execute_reply":"2024-05-20T04:52:43.416662Z"},"trusted":true,"id":"SKupQWxGr5hb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 표정 학습"],"metadata":{"id":"Wmkb1ti6r5hb"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from tqdm import tqdm\n","\n","def train(model, optimizer, train_loader, val_loader, scheduler, device, early_stopping_patience=3):\n","    model.to(device)\n","    criterion = torch.nn.CrossEntropyLoss().to(device)\n","    best_score = 0\n","    best_model = None\n","    patience = 0\n","\n","    for epoch in range(1, CFG['EPOCHS'] + 1):\n","        model.train()\n","        train_loss = []\n","        for imgs, labels in tqdm(iter(train_loader)):\n","            try:\n","                imgs = imgs.float().to(device)\n","                labels = labels.to(device)\n","                optimizer.zero_grad()\n","                output = model(imgs)\n","                loss = criterion(output, labels)\n","                loss.backward()\n","                optimizer.step()\n","                train_loss.append(loss.item())\n","            except:\n","                continue\n","\n","        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n","        _train_loss = np.mean(train_loss)\n","        current_lr = optimizer.param_groups[0][\"lr\"]\n","\n","        print(f'Epoch [{epoch}], Train Loss: [{_train_loss:.5f}], Val Loss: [{_val_loss:.5f}], Val F1 Score: [{_val_score:.5f}], Learning Rate: {current_lr}')\n","\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","\n","        if best_score < _val_score:\n","            best_score = _val_score\n","            best_model = model\n","            patience = 0\n","            torch.save(best_model, 'beitv2_large.pt')\n","        else:\n","            patience += 1\n","\n","\n","        if patience >= early_stopping_patience:\n","            print(f'Early stopping triggered at epoch {epoch}!')\n","            break\n","\n","    return best_model\n","\n","def validation(model, criterion, val_loader, device):\n","    model.eval()\n","    val_loss = []\n","    preds, true_labels = [], []\n","    with torch.no_grad():\n","        for imgs, labels in tqdm(iter(val_loader)):\n","            imgs = imgs.float().to(device)\n","            labels = labels.to(device)\n","            pred = model(imgs)\n","            loss = criterion(pred, labels)\n","            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n","            true_labels += labels.detach().cpu().numpy().tolist()\n","            val_loss.append(loss.item())\n","        _val_loss = np.mean(val_loss)\n","        _val_score = f1_score(true_labels, preds, average='macro')\n","    return _val_loss, _val_score\n"],"metadata":{"id":"cq4AaQCtr5hc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 성별 학습"],"metadata":{"id":"6Fhkk-UPr5hc"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score\n","import copy  # deep copy를 위해 import\n","\n","def train(model, optimizer, train_loader, val_loader, scheduler, device, early_stopping_patience=3):\n","    criterion = nn.BCEWithLogitsLoss().to(device)\n","    model.to(device)\n","    best_model = None\n","    best_loss = float('inf')\n","    patience = 0\n","\n","    for epoch in range(1, CFG['EPOCHS'] + 1):\n","        train_loss = []\n","        train_preds, train_gender_true = [], []\n","        model.train()\n","\n","        for img, gender in tqdm(iter(train_loader)):\n","            img = img.float().to(device)\n","            gender = gender.float().to(device)\n","            optimizer.zero_grad()\n","            output = model(img)\n","\n","            # 차원 맞추기\n","            output = output.view(-1)\n","            gender = gender.view(-1)\n","\n","            loss = criterion(output, gender)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss.append(loss.item())\n","            train_preds += (torch.sigmoid(output) > 0.5).int().detach().cpu().numpy().tolist()\n","            train_gender_true += gender.int().detach().cpu().numpy().tolist()\n","\n","        _train_loss = np.mean(train_loss)\n","        _train_acc = accuracy_score(train_gender_true, train_preds)\n","        _val_acc, _val_loss = validation(model, val_loader, criterion, device)\n","        current_lr = optimizer.param_groups[0]['lr']\n","\n","        print(f'Epoch [{epoch}], Train Loss: [{_train_loss:.5f}], Train Acc: [{_train_acc:.5f}], '\n","              f'Val Loss: [{_val_loss:.5f}], Val Acc: [{_val_acc:.5f}], Learning Rate: {current_lr}')\n","\n","        if scheduler is not None:\n","            scheduler.step(_val_loss)\n","\n","        if best_loss > _val_loss:\n","            best_loss = _val_loss\n","            best_model = copy.deepcopy(model)\n","            torch.save(best_model, 'swinv2_gender.pt')\n","            patience = 0\n","        else:\n","            patience += 1\n","\n","        if patience >= early_stopping_patience:\n","            print(f'Early stopping triggered at epoch {epoch}!')\n","            break\n","\n","    return best_model\n","\n","def validation(model, val_loader, criterion, device):\n","    model.eval()\n","    val_loss = []\n","    val_preds, val_gender_true = [], []\n","\n","    with torch.no_grad():\n","        for img, gender in tqdm(iter(val_loader)):\n","            img = img.float().to(device)\n","            gender = gender.float().to(device)\n","            pred = model(img)\n","\n","            # 차원 맞추기\n","            pred = pred.view(-1)\n","            gender = gender.view(-1)\n","\n","            loss = criterion(pred, gender)\n","\n","            val_preds += (torch.sigmoid(pred) > 0.5).int().detach().cpu().numpy().tolist()\n","            val_gender_true += gender.int().detach().cpu().numpy().tolist()\n","            val_loss.append(loss.item())\n","\n","        _val_loss = np.mean(val_loss)\n","        _val_acc = accuracy_score(val_gender_true, val_preds)\n","\n","    return _val_acc, _val_loss\n"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T06:13:57.329294Z","iopub.execute_input":"2024-05-20T06:13:57.329919Z","iopub.status.idle":"2024-05-20T06:13:57.349943Z","shell.execute_reply.started":"2024-05-20T06:13:57.329888Z","shell.execute_reply":"2024-05-20T06:13:57.349043Z"},"trusted":true,"id":"iVo1-Kgfr5hc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 나이 학습"],"metadata":{"id":"nEPEfxrUr5hd"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.metrics import mean_absolute_error\n","import copy\n","\n","def train(model, optimizer, train_loader, val_loader, scheduler, device, early_stopping_patience=3):\n","    criterion = nn.MSELoss().to(device)\n","    model.to(device)\n","    best_model = None\n","    best_loss = float('inf')\n","    patience = 0\n","\n","    for epoch in range(1,CFG['EPOCHS']+1):\n","        train_loss = []\n","        train_preds, train_age_true = [], []\n","        model.train()\n","\n","        for img, age in tqdm(iter(train_loader)):\n","            img = img.float().to(device)\n","            age = age.float().to(device)\n","            optimizer.zero_grad()\n","            output = model(img)\n","            loss = criterion(output, age)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss.append(loss.item())\n","            train_preds += output.detach().cpu().numpy().tolist()\n","            train_age_true += age.detach().cpu().numpy().tolist()\n","        _train_loss=np.mean(train_loss)\n","        _train_mae = mean_absolute_error(train_age_true, train_preds)\n","        _val_mae, _val_loss= validation(model, val_loader, criterion, device)\n","        current_lr = optimizer.param_groups[0]['lr']\n","\n","        print(f'Epoch [{epoch}], Train MAE: [{_train_mae:.5f}], Train Loss: [{_train_loss:.5f}], Val MAE: [{_val_mae:.5f}], Val Loss: [{_val_loss:.5f}], Learning Rate: {current_lr}')\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        if best_loss > _val_mae:\n","            best_loss = _val_mae\n","            best_model = copy.deepcopy(model)\n","            torch.save(best_model, 'swinv2_age.pt')\n","            patience = 0\n","        else:\n","            patience += 1\n","\n","        if patience >= early_stopping_patience:\n","            print(f'Early stopping triggered at epoch {epoch}!')\n","            break\n","\n","    return best_model\n","\n","def validation(model, val_loader, criterion, device):\n","    model.eval()\n","    val_loss = []\n","    val_preds, val_age_true = [], []\n","\n","    with torch.no_grad():\n","        for img, age in tqdm(iter(val_loader)):\n","            img = img.float().to(device)\n","            age = age.float().to(device)\n","            pred = model(img)\n","            loss = criterion(pred, age)  # pred를 squeeze하여 차원을 맞춤\n","\n","            val_preds += pred.detach().cpu().numpy().tolist()  # flatten을 사용하여 1차원 배열로 변환\n","            val_age_true += age.detach().cpu().numpy().tolist()\n","            val_loss.append(loss.item())\n","        _val_loss=np.mean(val_loss)\n","        _val_mae = mean_absolute_error(val_age_true, val_preds)\n","\n","    return _val_mae, _val_loss\n"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:02:03.705949Z","iopub.execute_input":"2024-05-20T05:02:03.706820Z","iopub.status.idle":"2024-05-20T05:02:03.724566Z","shell.execute_reply.started":"2024-05-20T05:02:03.706785Z","shell.execute_reply":"2024-05-20T05:02:03.723578Z"},"trusted":true,"id":"7w27M7nBr5hd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","optimizer=torch.optim.AdamW(params=model.parameters(),lr=CFG['LEARNING_RATE'])\n","scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=10)\n","infer_model=train(model,optimizer,train_loader,val_loader,scheduler,device)"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T06:14:00.459346Z","iopub.execute_input":"2024-05-20T06:14:00.459815Z","iopub.status.idle":"2024-05-20T07:51:54.347122Z","shell.execute_reply.started":"2024-05-20T06:14:00.459782Z","shell.execute_reply":"2024-05-20T07:51:54.346024Z"},"trusted":true,"id":"L8QfKjYFr5hd","outputId":"5dc3069c-7ce7-4e11-c7d6-127e0a71d2b1"},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 369/369 [17:20<00:00,  2.82s/it]\n100%|██████████| 73/73 [02:12<00:00,  1.82s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1], Train Loss: [0.01439], Train Acc: [0.99575], Val Loss: [0.02683], Val Acc: [0.99057], Learning Rate: 1e-05\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 369/369 [17:25<00:00,  2.83s/it]\n100%|██████████| 73/73 [02:08<00:00,  1.76s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2], Train Loss: [0.00439], Train Acc: [0.99830], Val Loss: [0.13300], Val Acc: [0.97942], Learning Rate: 9.999289656187745e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 369/369 [17:24<00:00,  2.83s/it]\n100%|██████████| 73/73 [02:17<00:00,  1.89s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3], Train Loss: [0.00844], Train Acc: [0.99796], Val Loss: [0.01715], Val Acc: [0.99400], Learning Rate: 9.98255114040809e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 369/369 [17:27<00:00,  2.84s/it]\n100%|██████████| 73/73 [02:09<00:00,  1.77s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4], Train Loss: [0.00777], Train Acc: [0.99864], Val Loss: [0.03346], Val Acc: [0.99400], Learning Rate: 9.999709810960851e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 369/369 [17:12<00:00,  2.80s/it]\n100%|██████████| 73/73 [02:10<00:00,  1.79s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [5], Train Loss: [0.00069], Train Acc: [0.99983], Val Loss: [0.05577], Val Acc: [0.98542], Learning Rate: 9.998894880263873e-06\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}